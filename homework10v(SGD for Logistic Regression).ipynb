{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milesba4/CS158-ML/blob/main/homework10v(SGD%20for%20Logistic%20Regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Homework 10**"
      ],
      "metadata": {
        "id": "FZ0um49rzsKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start with a few imports and our running library of functions."
      ],
      "metadata": {
        "id": "7pR7ZPp9zzik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n",
        "def TrainTestSplit(X,y,p,seed=1):\n",
        "  '''Splits feature matrix X and target array y into train and test sets\n",
        "  p is the fraction going to train'''\n",
        "  np.random.seed(seed) #controls randomness\n",
        "  size=len(y) \n",
        "  train_size=int(p*size)\n",
        "  train_mask=np.zeros(size,dtype=bool)\n",
        "  train_indices=np.random.choice(size, train_size, replace=False)\n",
        "  train_mask[train_indices]=True \n",
        "  test_mask=~train_mask\n",
        "  X_train=X[train_mask]\n",
        "  X_test=X[test_mask]\n",
        "  y_train=y[train_mask]\n",
        "  y_test=y[test_mask]\n",
        "  return X_train,X_test,y_train,y_test\n",
        "\n",
        "def PolyFeatures(x,d):\n",
        "  X=np.zeros((len(x),d+1))\n",
        "  for i in range(d+1):\n",
        "    X[:,i]=x**i\n",
        "  return X\n",
        "\n",
        "def AddOnes(X):\n",
        "  return np.concatenate((X,np.ones((len(X),1))),axis=1)\n",
        "\n",
        "class Scaler:\n",
        "  def __init__(self,z):\n",
        "    self.min=np.min(z,axis=0)\n",
        "    self.max=np.max(z,axis=0)\n",
        "\n",
        "  def scale(self,x):\n",
        "    return (x-self.min)/(self.max-self.min)\n",
        "\n",
        "  def unscale(self,x):\n",
        "    return x*(self.max-self.min)+self.min\n",
        "\n",
        "def train(X,y,max_iter,lr):\n",
        "  '''MSE minimization by Gradient Descent'''\n",
        "  X=np.array(X) #Just in case X is a DataFrame\n",
        "  y=np.array(y) #Just in case y is a Series\n",
        "  n=len(X)\n",
        "  coeff=np.ones(X.shape[1]) #Initialize all coeff to be 1 (something to play with?)\n",
        "  for i in range(max_iter):\n",
        "    resid=X@coeff-y\n",
        "    gradient=((X.T)@resid)/n #Lot's of lin alg here. Try to unpack it!\n",
        "    coeff=coeff-lr*gradient #Gradient Descent step.\n",
        "  return coeff\n",
        "\n",
        "def SGD(X,y,epochs,batch_size,lr,alpha=0,beta=0):\n",
        "  '''Stochastic Gradient Descent With L1 and L2 regularization'''\n",
        "  #alpha=amount of L1 (Lasso) regularization\n",
        "  #beta=amount of L2 (Ridge) regularization\n",
        "  X=np.array(X) #Just in case X is a DataFrame\n",
        "  y=np.array(y) #Just in case y is a Series\n",
        "  n=len(X)\n",
        "  coeff=np.ones(X.shape[1]) #Initialize all coeff to be 1 (something to play with?)\n",
        "  indices=np.arange(len(X))\n",
        "  for i in range(epochs):\n",
        "    np.random.seed(i)\n",
        "    np.random.shuffle(indices)\n",
        "    X_shuffle=X[indices] \n",
        "    y_shuffle=y[indices] \n",
        "    num_batches=n//batch_size\n",
        "    for j in range(num_batches):\n",
        "      X_batch=X_shuffle[j*batch_size:(j+1)*batch_size]\n",
        "      y_batch=y_shuffle[j*batch_size:(j+1)*batch_size]\n",
        "      resid=X_batch@coeff-y_batch\n",
        "      gradient=lr*((X_batch.T)@resid)/len(X_batch)+alpha*(2*(coeff>0)-1)+beta*coeff\n",
        "      coeff=coeff-gradient #Gradient Descent step.\n",
        "    if n%batch_size!=0: #Check if there is a smaller leftover batch\n",
        "      X_batch=X_shuffle[num_batches*batch_size:] #last batch\n",
        "      y_batch=y_shuffle[num_batches*batch_size:] #last batch\n",
        "      resid=X_batch@coeff-y_batch\n",
        "      gradient=lr*((X_batch.T)@resid)/len(X_batch)+alpha*(2*(coeff>0)-1)+beta*coeff\n",
        "      coeff=coeff-gradient \n",
        "  return coeff\n",
        "\n",
        "def predict(X,coeff): #If X was scaled, then this will return scaled predictions\n",
        "  return X@coeff\n",
        "\n",
        "def MSE(pred,y):\n",
        "  return np.sum((pred-y)**2)/len(y)"
      ],
      "metadata": {
        "id": "o3bG8pKfzy4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll load the iris dataset as a pandas DataFrame."
      ],
      "metadata": {
        "id": "MuPrvVge0Gb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris=(pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv',index_col=0))"
      ],
      "metadata": {
        "id": "AibXEthd0F73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment you'll create a general Logistic Regression funcation, and train it to predict which flowers are virginicas just from their petal length and width. Since this is a very simple dataset, we won't worry about doing a train/test split, scaling, etc. \n",
        "\n",
        "To begin, we select the `Petal.Length` and `Petal.Width` columns to be our features `X`, and for our target `y` we'll create a boolean array which is True if the species is virginica, and False otherwise. "
      ],
      "metadata": {
        "id": "tsojVh_CkD0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(iris[['Petal.Length','Petal.Width']])\n",
        "X=AddOnes(X)\n",
        "y=np.array(iris['Species']=='virginica')"
      ],
      "metadata": {
        "id": "tcOb3sPWkDWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, define a function `sigmoid` by the following formula:\n",
        "$$\\sigma(t)=\\frac{1}{1+e^{-t}}$$\n",
        "\n",
        "Be sure to use np.exp, and not math.exp, so that all operations are vectorized."
      ],
      "metadata": {
        "id": "27vFXND6mQNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(t):\n",
        "  return 1/(1+(math.exp(1)**(-t)))"
      ],
      "metadata": {
        "id": "mOufNgpBmlPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we are after is to find values of m, n, and b so that $$\\sigma(m*length+n*width+b)$$ is a good predictor of the probability of a flower being a virginica. \n",
        "\n",
        "In general, for a feature matrix `X` (with a column of ones), we want to find a vector of coefficients `coeff` so that $\\sigma$(X@coeff) is a good predictor of the target column.   \n",
        "\n",
        "Define a function `proba` that gives the value of this probability. "
      ],
      "metadata": {
        "id": "PUjbGgjFmpPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def proba(X,coeff): \n",
        "  return sigmoid(X@coeff)"
      ],
      "metadata": {
        "id": "FfckWF6InUkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a logistic model defined by m=-2, n=0.5, and b=10 to generate an array of probabilities for the matrix X of petal lengths and widths (don't forget to add a column of ones!). "
      ],
      "metadata": {
        "id": "YA99XHRM5WpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeff=np.array([-2,.5,10])\n",
        "\n",
        "probs=proba(X,coeff)\n",
        "probs"
      ],
      "metadata": {
        "id": "IGPLB12q5aHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9781b990-8603-43d9-80d2-adffe58dec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99932492, 0.99932492, 0.99944722, 0.99917558, 0.99932492,\n",
              "       0.99888746, 0.99935782, 0.99917558, 0.99932492, 0.99913334,\n",
              "       0.99917558, 0.99899323, 0.99929033, 0.9996104 , 0.99954738,\n",
              "       0.99925397, 0.9994998 , 0.99935782, 0.99883049, 0.99921575,\n",
              "       0.9987706 , 0.99925397, 0.99969655, 0.99894167, 0.99816706,\n",
              "       0.99899323, 0.99908895, 0.99917558, 0.99932492, 0.99899323,\n",
              "       0.99899323, 0.99925397, 0.99913334, 0.99932492, 0.99917558,\n",
              "       0.99954738, 0.99944722, 0.99929033, 0.99944722, 0.99917558,\n",
              "       0.99947417, 0.99947417, 0.99944722, 0.99917558, 0.9983412 ,\n",
              "       0.99935782, 0.99899323, 0.99932492, 0.99917558, 0.99932492,\n",
              "       0.78583498, 0.8519528 , 0.72111518, 0.93401099, 0.82491373,\n",
              "       0.83889105, 0.80218389, 0.98015969, 0.80999843, 0.94784644,\n",
              "       0.97068777, 0.91293423, 0.92414182, 0.78583498, 0.96923114,\n",
              "       0.86989153, 0.8519528 , 0.90887704, 0.8519528 , 0.93991335,\n",
              "       0.78583498, 0.93401099, 0.72111518, 0.76852478, 0.88594762,\n",
              "       0.86989153, 0.75026011, 0.70056714, 0.8519528 , 0.97068777,\n",
              "       0.95026349, 0.95689275, 0.94267582, 0.64565631, 0.8519528 ,\n",
              "       0.85814894, 0.79412963, 0.8641271 , 0.92056145, 0.93401099,\n",
              "       0.85814894, 0.81757448, 0.93086158, 0.98015969, 0.90465054,\n",
              "       0.90024951, 0.90465054, 0.88594762, 0.98954329, 0.92056145,\n",
              "       0.3208213 , 0.6791787 , 0.3208213 , 0.42555748, 0.37754067,\n",
              "       0.10433122, 0.8641271 , 0.15446527, 0.33181223, 0.27888482,\n",
              "       0.68997448, 0.58661758, 0.5124974 , 0.73105858, 0.73105858,\n",
              "       0.63413559, 0.47502081, 0.09112296, 0.06598901, 0.6791787 ,\n",
              "       0.4378235 , 0.76852478, 0.0831727 , 0.75026011, 0.41338242,\n",
              "       0.24973989, 0.78583498, 0.75026011, 0.46257015, 0.31002552,\n",
              "       0.22270014, 0.14185106, 0.47502081, 0.63413559, 0.37754067,\n",
              "       0.2592251 , 0.5       , 0.47502081, 0.78583498, 0.5621765 ,\n",
              "       0.5       , 0.72111518, 0.6791787 , 0.34298954, 0.46257015,\n",
              "       0.6791787 , 0.72111518, 0.64565631, 0.58661758, 0.66818777])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function `predict` that takes an array of probabilities and returns True for each one that is above 0.5, and False otherwise. Then, use this function to make predictions on weather or not each flower is a virginica, based on the logistic model with coefficients m=-2, n=0.5, and b=10."
      ],
      "metadata": {
        "id": "dI72dhoE5yCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(probs):\n",
        "  #takes an array of probabilities and returns True for each one that is above 0.5, and False otherwise\n",
        "  \n",
        "  return (probs >.5)\n",
        "\n",
        "predictions=predict(probs)\n",
        "predictions"
      ],
      "metadata": {
        "id": "ZCQCra4X58HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefe067f-414c-4c2a-a3f4-20db738c2698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True, False,  True, False, False, False, False,  True, False,\n",
              "       False, False,  True,  True,  True,  True,  True,  True, False,\n",
              "       False, False,  True, False,  True, False,  True, False, False,\n",
              "        True,  True, False, False, False, False, False,  True, False,\n",
              "       False, False, False,  True,  True, False,  True,  True, False,\n",
              "       False,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function `accuracy` that takes an array of predicted True/False values and an array of target True/False values, and determines the accuracy of the predictions. Then, use this to determine the accuracy of the logistic model with coefficients m=-2, n=0.5, and b=10."
      ],
      "metadata": {
        "id": "7x-eNtYjoi46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred,y):\n",
        "  #takes an array or predicted True/False values and an array of target True/False values, and determines the accuracy of the predictions.\n",
        "  matching_arr=(pred==y)\n",
        "  accuracy=sum(matching_arr)/len(matching_arr)\n",
        "  return accuracy\n",
        "\n",
        "acc=accuracy(predictions,y)\n",
        "acc"
      ],
      "metadata": {
        "id": "jb0YlNK56pYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edfc82c3-c212-4165-e882-343dea7b16d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15333333333333332"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function we will optimize is not accuracy, but rather the log of the probability that our guesses for the target column are correct, if we guess according to the probabilities given by our model (log-loss). To compute this, define a function that calculates the *mean* log loss. Then, apply this function to the logistic model with coefficients m=-2, n=0.5, and b=10. As discussed in class, the log loss is given by:\n",
        "\n",
        "$$\\log \\left(\\prod \\limits _{target_i=T} p_i \\cdot \\prod \\limits _{target_i=F} (1-p_i)\\right)\\\\\n",
        "=\\sum \\limits _{target_i=T} \\log(p_i) + \\sum \\limits _{target_i=F} \\log(1-p_i)\\\\\n",
        "=\\sum \\limits _i  target_i \\log(p_i) +  (1-target_i)\\log(1-p_i)$$\n",
        "\n",
        "As in the case of RSS vs MSE, the mean log loss is obtained from the log loss by dividing by the number of rows in our dataset, to account for datasets of varying size. "
      ],
      "metadata": {
        "id": "tM57Y1dYpY3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LogLoss(probs,y):\n",
        "  return sum(y*np.log(probs)+(1-y)*np.log(1-probs))\n",
        "\n",
        "LL=LogLoss(probs,y)/len(y)\n",
        "LL"
      ],
      "metadata": {
        "id": "NePpvEVBrzBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55690be6-f683-4a87-dace-f8db63de21e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3.4500448158079577"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above quantity is a number between $-\\infty$ and $0$, with numbers closer to 0 being better. Rather than maximize this, we will minimze its negation (i.e. we'll put a negative sign in front and use gradient descent). \n",
        "\n",
        "For example, in the case of our iris model, the gradient of the mean log loss is given by the three partial derivatives:\n",
        "$$\\frac{\\partial ll}{\\partial m}= \\frac{1}{len(y)}\\sum \\limits _i (p_i-target_i)length_i$$\n",
        "$$\\frac{\\partial ll}{\\partial n}= \\frac{1}{len(y)}\\sum \\limits _i (p_i-target_i)width_i$$\n",
        "$$\\frac{\\partial ll}{\\partial b}= \\frac{1}{len(y)}\\sum \\limits _i (p_i-target_i)$$\n",
        "\n",
        "Again, we will also divide these by the number of rows in our dataset, to account for datasets of varying size. "
      ],
      "metadata": {
        "id": "BRSN9ovRr2LI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, if you have a feature matrix X and a logistic model giving probabilities `proba` for a target `y` then the gradient vector is given by `X.T@(proba-y)/len(X)`. \n",
        "\n",
        "Use this to modify the SGD function defined in the previous homework assignment to find an optimal Logistic regression model. As before, we will use stochastic (batch) gradient descent, with possible L1 and L2 regularization."
      ],
      "metadata": {
        "id": "19Czn6FbwuR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LogisticSGD(X,y,epochs,batch_size,lr,alpha=0,beta=0):\n",
        "  '''Stochastic Gradient Descent for Logistic Regression'''\n",
        "  #alpha=amount of L1 (Lasso) regularization\n",
        "  #beta=amount of L2 (Ridge) regularization\n",
        "  X=np.array(X) #Just in case X is a DataFrame\n",
        "  y=np.array(y) #Just in case y is a Series\n",
        "  n=len(X)\n",
        "  coeff=np.ones(X.shape[1]) #Initialize all coeff to be 1 (something to play with?)\n",
        "  indices=np.arange(len(X))\n",
        "  for i in range(epochs):\n",
        "    np.random.seed(i)\n",
        "    np.random.shuffle(indices)\n",
        "    X_shuffle=X[indices] \n",
        "    y_shuffle=y[indices] \n",
        "    num_batches=n//batch_size\n",
        "    for j in range(num_batches):\n",
        "      X_batch=X_shuffle[j*batch_size:(j+1)*batch_size]\n",
        "      y_batch=y_shuffle[j*batch_size:(j+1)*batch_size]\n",
        "      resid=X_batch@coeff-y_batch\n",
        "      gradient=(lr*(X_batch.T@(proba(X_batch,coeff)-y_batch))/len(X_batch))+alpha*(2*(coeff>0)-1)+beta*coeff\n",
        "      coeff=coeff-gradient #Gradient Descent step.\n",
        "    if n%batch_size!=0: #Check if there is a smaller leftover batch\n",
        "      X_batch=X_shuffle[num_batches*batch_size:] #last batch\n",
        "      y_batch=y_shuffle[num_batches*batch_size:] #last batch\n",
        "      resid=X_batch@coeff-y_batch\n",
        "      gradient=(lr*(X_batch.T@(proba(X_batch,coeff)-y_batch))/len(X_batch))+alpha*(2*(coeff>0)-1)+beta*coeff\n",
        "      coeff=coeff-gradient \n",
        "  return coeff"
      ],
      "metadata": {
        "id": "jLJK55eU0o0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this function to compute coefficients for a logistic model for the feature matrix X (with a columns of ones added) and target y. Run your code for 2000 epochs, with batch sizes of 50, and learning rate 0.01. For this assignment, we won't worry about regularization, so leave alpha and beta at 0. "
      ],
      "metadata": {
        "id": "_yp0AqJOm7PH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nD60Gduwwkm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newcoeff=LogisticSGD(X,y,2000,50,.01,0,0)\n",
        "newcoeff"
      ],
      "metadata": {
        "id": "o_0bEXPD9uyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decc74cb-b89c-4e3b-c597-283d7b9e2548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.17670254,  2.73978481, -3.55043789])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the accuracy of the logistic model you found with these coefficients."
      ],
      "metadata": {
        "id": "U1SCskJXnLAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_probs=proba(X,newcoeff)\n",
        "new_predictions=predict(new_probs)\n",
        "newaccuracy=accuracy(new_predictions,y)\n",
        "newaccuracy"
      ],
      "metadata": {
        "id": "l_QH7DV3t4WF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69f3312-83a7-44cf-cfa2-5d43f8018f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9466666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the \"decision boundary\" between where your model will predict virginica (in blue) vs the other species, run the following code block:"
      ],
      "metadata": {
        "id": "d-_Vobu0HzK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func(x):\n",
        "  m=-newcoeff[0]/newcoeff[1]\n",
        "  b=-newcoeff[2]/newcoeff[1]\n",
        "  return m*x+b\n",
        "\n",
        "cdict={'versicolor':'r','setosa':'g','virginica':'b'}\n",
        "colors=iris.apply(lambda x:cdict[x.Species],axis=1)\n",
        "\n",
        "plt.scatter(X[:,0],X[:,1],c=colors)\n",
        "plt.plot(X[:,0],func(X[:,0]))"
      ],
      "metadata": {
        "id": "JYnGnyk_zEIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ab4eb54c-019b-4cda-d3e5-e788a223e6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f871a8ae100>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}