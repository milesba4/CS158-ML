{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milesba4/CS158-ML/blob/main/homework3%20(KNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Homework 3**"
      ],
      "metadata": {
        "id": "G8OReEGoBUyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment is a continuation of homework 2. Make sure you complete that first!. \n",
        "\n",
        "We begin with the usual imports."
      ],
      "metadata": {
        "id": "BxOCrr74BYky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyeQSz7hP6MN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now load the iris dataset."
      ],
      "metadata": {
        "id": "ENoFBgC2Bcvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris=pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv\",index_col=0)"
      ],
      "metadata": {
        "id": "5pStLgrIQCQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code block below copy your code from homework 2 that defines the function `KNN`, together with all of the helper functions."
      ],
      "metadata": {
        "id": "GBdJliDCOEIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = iris.Species \n",
        "#Generate list of sq distances \n",
        "def sq_distances(data,length,width):\n",
        "  return(((data[\"Petal.Length\"]-length)**2) + ((data[\"Petal.Width\"]-width)**2))\n",
        "#Extract Species of nearest K neighbors\n",
        "def SpeciesOfKNeighbors(data,target,x,y,k):\n",
        "  return(target.loc[sq_distances(data,x,y).sort_values().iloc[0:k].index])\n",
        "#Extract most common species of closest K neigbors\n",
        "def prediction(labels):\n",
        "  return(labels.value_counts().sort_values().index[0])\n",
        "#Return prediction\n",
        "def KNN(data,target,x,y,k):\n",
        "  distances = sq_distances(data,x,y)\n",
        "  labels = SpeciesOfKNeighbors(data,target,x,y,k)\n",
        "  return prediction(labels)\n"
      ],
      "metadata": {
        "id": "ftP1j3YeOV8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The iris dataset contains 150 observations. We'd like to set aside 20% of these for testing the accuracy of our model(s). In the code block below, we create a Numpy array `test_indices` with a random sample of 20% of the numbers from 0 to 149. Then, we create a boolean Numpy array with a value of True for each index listed in `test_indices`, and False for the other values. Finally, we create a boolean Numpy array `train_mask` with the negation of each entry in `test_mask`. Spend some time examining the commands in the code block to make sure you understand them."
      ],
      "metadata": {
        "id": "Z74yJjWgBmx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(6) #controls randomness. Do not change!\n",
        "size=len(iris)  #size of original dataset (should be 150 for iris)\n",
        "test_frac=0.2 #fraction of dataset to set aside for testing\n",
        "test_size=int(size*test_frac) #desired size of test dataset \n",
        "test_indices=np.random.choice(np.arange(size),test_size) #random sample of indices from iris\n",
        "test_mask=np.zeros(size,dtype=bool) #numpy array of False values\n",
        "test_mask[test_indices]=True #change values at desired indices to True\n",
        "train_mask=~test_mask #True->False, False->True\n",
        "test_mask"
      ],
      "metadata": {
        "id": "5flT2IxHCFIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c809a9c3-57f4-4829-e783-3b82e19e69c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False, False, False, False, False, False,  True,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "       False, False, False, False, False, False, False,  True,  True,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "        True, False, False,  True, False,  True, False, False, False,\n",
              "       False, False, False,  True, False,  True, False,  True,  True,\n",
              "       False, False, False, False,  True,  True, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False,  True, False,\n",
              "       False,  True,  True, False, False, False,  True, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "       False,  True, False, False,  True, False,  True,  True, False,\n",
              "       False, False, False,  True, False, False, False, False, False,\n",
              "       False, False, False,  True, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define `test_data` to be a DataFrame containing the `Petal.Length` and `Petal.Width` of the rows specified by `test_mask`. Define `test_target` to be a Pandas Series containing the `Species` of those rows. Define `train_data` and `train_target` similarly. "
      ],
      "metadata": {
        "id": "NFTIGfRwFqfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=iris[train_mask[iris.index-1]==True]\n",
        "train_target=train_data[\"Species\"]\n",
        "test_data=iris[test_mask[iris.index-1]==True]\n",
        "test_target=test_data[\"Species\"]\n",
        "test_data\n"
      ],
      "metadata": {
        "id": "IGRadmhsE25D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "6b93b69a-52f7-4095-ae4c-c9b6ceb3922c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width     Species\n",
              "2             4.9          3.0           1.4          0.2      setosa\n",
              "9             4.4          2.9           1.4          0.2      setosa\n",
              "16            5.7          4.4           1.5          0.4      setosa\n",
              "26            5.0          3.0           1.6          0.2      setosa\n",
              "27            5.0          3.4           1.6          0.4      setosa\n",
              "32            5.4          3.4           1.5          0.4      setosa\n",
              "63            6.0          2.2           4.0          1.0  versicolor\n",
              "64            6.1          2.9           4.7          1.4  versicolor\n",
              "67            5.6          3.0           4.5          1.5  versicolor\n",
              "69            6.2          2.2           4.5          1.5  versicolor\n",
              "76            6.6          3.0           4.4          1.4  versicolor\n",
              "78            6.7          3.0           5.0          1.7  versicolor\n",
              "80            5.7          2.6           3.5          1.0  versicolor\n",
              "81            5.5          2.4           3.8          1.1  versicolor\n",
              "86            6.0          3.4           4.5          1.6  versicolor\n",
              "87            6.7          3.1           4.7          1.5  versicolor\n",
              "107           4.9          2.5           4.5          1.7   virginica\n",
              "110           7.2          3.6           6.1          2.5   virginica\n",
              "111           6.5          3.2           5.1          2.0   virginica\n",
              "115           5.8          2.8           5.1          2.4   virginica\n",
              "126           7.2          3.2           6.0          1.8   virginica\n",
              "128           6.1          3.0           4.9          1.8   virginica\n",
              "131           7.4          2.8           6.1          1.9   virginica\n",
              "133           6.4          2.8           5.6          2.2   virginica\n",
              "134           6.3          2.8           5.1          1.5   virginica\n",
              "139           6.0          3.0           4.8          1.8   virginica\n",
              "148           6.5          3.0           5.2          2.0   virginica"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aa74d77-746f-497e-97fd-cc3c06a9053e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sepal.Length</th>\n",
              "      <th>Sepal.Width</th>\n",
              "      <th>Petal.Length</th>\n",
              "      <th>Petal.Width</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>5.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>6.2</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>6.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>7.2</td>\n",
              "      <td>3.6</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.4</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>7.2</td>\n",
              "      <td>3.2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>6.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>7.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aa74d77-746f-497e-97fd-cc3c06a9053e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6aa74d77-746f-497e-97fd-cc3c06a9053e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6aa74d77-746f-497e-97fd-cc3c06a9053e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function called `predict_labels` whose inputs are `train_data`, `train_target`, `test_data` and `k`. Your function should output a Series of labels (one for each entry in `test_data`) that are predicted by your KNN function, based on the k-closest points in train_data. \n",
        "\n",
        "*Hints.* There are many ways to do this. Here are two possibilities:\n",
        "1. Use the Pandas command `apply` and a lambda function. (strongly preferred)\n",
        "2. Use a \"for loop\", collect your answers in a list, and then convert to a Pandas Series object."
      ],
      "metadata": {
        "id": "N12LgAjPvPvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_labels(train_data,train_target,test_data,k):\n",
        "   return(test_data.apply(lambda row: KNN(train_data,train_target,row[2],row[3],k),axis=1))\n",
        "\n",
        "predict_labels(train_data,train_target,test_data, 5)"
      ],
      "metadata": {
        "id": "ISuM05KzwV1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98c097e-c720-402f-a2ff-42b0e7dd8310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2          setosa\n",
              "9          setosa\n",
              "16         setosa\n",
              "26         setosa\n",
              "27         setosa\n",
              "32         setosa\n",
              "63     versicolor\n",
              "64     versicolor\n",
              "67     versicolor\n",
              "69     versicolor\n",
              "76     versicolor\n",
              "78     versicolor\n",
              "80     versicolor\n",
              "81     versicolor\n",
              "86     versicolor\n",
              "87     versicolor\n",
              "107    versicolor\n",
              "110     virginica\n",
              "111     virginica\n",
              "115     virginica\n",
              "126     virginica\n",
              "128    versicolor\n",
              "131     virginica\n",
              "133     virginica\n",
              "134     virginica\n",
              "139    versicolor\n",
              "148     virginica\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function called `accuracy` whose inputs are `train_data`, `train_target`, `test_data`, `test_target` and `k`. Your function should return the accuracy: the fraction of times your `predict_labels` function returned the correct answer."
      ],
      "metadata": {
        "id": "iSyTNqCMxrGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(train_data,train_target,test_data,test_target,k):\n",
        "  #number of correct entries\n",
        "  acc_series = pd.Series()\n",
        "  acc_series['Accuracy'] = np.where(test_target == predict_labels(train_data,train_target,test_data, k), 0, 1) \n",
        "  num_acc = sum(acc_series.iloc[0])\n",
        "  accuracy = num_acc/ len(test_data)\n",
        "  return accuracy\n",
        "accuracy(train_data,train_target,test_data,test_target,5)"
      ],
      "metadata": {
        "id": "z5vca56CVZqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f25f5e0-269e-42ee-f6d2-c06d4f774ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-85-6ad7471e1ce4>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  acc_series = pd.Series()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1111111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to visualize the accuracy of our KNN algorithm for various values of k, so we may pick the best one. Reasonable values of k start at 3, and may go as high as 20 (depending on the application). For each such value of k, compute the accuracy and assemble these in a 1D Numpy array."
      ],
      "metadata": {
        "id": "fsg8NrNU0Z53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_values=np.arange(3,20) #possible values for k\n",
        "\n",
        "accuracies=np.array([accuracy(train_data,train_target,test_data,test_target,x) for x in k_values])\n",
        "accuracies"
      ],
      "metadata": {
        "id": "bFk975Zms6nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae16ac6d-74e5-44aa-b341-57415a4900d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-e0a608cfd184>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  acc_series = pd.Series()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11111111, 0.11111111, 0.11111111, 0.07407407, 0.07407407,\n",
              "       0.07407407, 0.11111111, 0.07407407, 0.07407407, 0.11111111,\n",
              "       0.22222222, 0.18518519, 0.22222222, 0.22222222, 0.22222222,\n",
              "       0.25925926, 0.25925926])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code block to visualize:"
      ],
      "metadata": {
        "id": "7VcxngjC19Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(k_values,accuracies)"
      ],
      "metadata": {
        "id": "5H_tVLXWtBUC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9f3e6ea4-08d1-4b41-b336-659d03b7cb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe97cb1e0d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal value of k will be the first odd number appearing at a maximum (think about why). What is it? "
      ],
      "metadata": {
        "id": "JxPJWw43z8ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k=5"
      ],
      "metadata": {
        "id": "InnWAMB_tUBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}